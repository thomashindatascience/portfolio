{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "nlp-sequence-models",
      "graded_item_id": "n16CQ",
      "launcher_item_id": "npjGi"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "colab": {
      "name": "Machine translation with NN attention model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gary-kaitung/Machine-translation-with-NN-attention-model/blob/master/Machine_translation_with_NN_attention_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2qXCtNgYo-b",
        "colab_type": "text"
      },
      "source": [
        "# Neural Machine Translation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1o3NITaYo-f",
        "colab_type": "code",
        "colab": {},
        "outputId": "2a6b55b5-3f16-4331-d6d2-74bead34054c"
      },
      "source": [
        "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
        "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model, Model\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "\n",
        "from faker import Faker\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from babel.dates import format_date\n",
        "from nmt_utils import *\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8ooPfrxYo-u",
        "colab_type": "code",
        "colab": {},
        "outputId": "56f9a356-a696-4013-eb36-c5e8ce64015e"
      },
      "source": [
        "m = 10000\n",
        "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:01<00:00, 9684.64it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqR5dcOrYo-z",
        "colab_type": "code",
        "colab": {},
        "outputId": "8710e8c5-dce3-4e89-98a1-159e0fb238e2"
      },
      "source": [
        "dataset[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('9 may 1998', '1998-05-09'),\n",
              " ('10.09.70', '1970-09-10'),\n",
              " ('4/28/90', '1990-04-28'),\n",
              " ('thursday january 26 1995', '1995-01-26'),\n",
              " ('monday march 7 1983', '1983-03-07'),\n",
              " ('sunday may 22 1988', '1988-05-22'),\n",
              " ('tuesday july 8 2008', '2008-07-08'),\n",
              " ('08 sep 1999', '1999-09-08'),\n",
              " ('1 jan 1981', '1981-01-01'),\n",
              " ('monday may 22 1995', '1995-05-22')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4jc9I2dYo-4",
        "colab_type": "code",
        "colab": {},
        "outputId": "b28192bd-f809-472e-fc6f-8585600704bc"
      },
      "source": [
        "Tx = 30\n",
        "Ty = 10\n",
        "X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)\n",
        "\n",
        "print(\"X.shape:\", X.shape)\n",
        "print(\"Y.shape:\", Y.shape)\n",
        "print(\"Xoh.shape:\", Xoh.shape)\n",
        "print(\"Yoh.shape:\", Yoh.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X.shape: (10000, 30)\n",
            "Y.shape: (10000, 10)\n",
            "Xoh.shape: (10000, 30, 37)\n",
            "Yoh.shape: (10000, 10, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFURu0HMYo-9",
        "colab_type": "code",
        "colab": {},
        "outputId": "c4c0e509-ee10-4dce-b44b-bb34006cf73b"
      },
      "source": [
        "index = 0\n",
        "print(\"Source date:\", dataset[index][0])\n",
        "print(\"Target date:\", dataset[index][1])\n",
        "print()\n",
        "print(\"Source after preprocessing (indices):\", X[index])\n",
        "print(\"Target after preprocessing (indices):\", Y[index])\n",
        "print()\n",
        "print(\"Source after preprocessing (one-hot):\", Xoh[index])\n",
        "print(\"Target after preprocessing (one-hot):\", Yoh[index])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source date: 9 may 1998\n",
            "Target date: 1998-05-09\n",
            "\n",
            "Source after preprocessing (indices): [12  0 24 13 34  0  4 12 12 11 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
            " 36 36 36 36 36]\n",
            "Target after preprocessing (indices): [ 2 10 10  9  0  1  6  0  1 10]\n",
            "\n",
            "Source after preprocessing (one-hot): [[ 0.  0.  0. ...,  0.  0.  0.]\n",
            " [ 1.  0.  0. ...,  0.  0.  0.]\n",
            " [ 0.  0.  0. ...,  0.  0.  0.]\n",
            " ..., \n",
            " [ 0.  0.  0. ...,  0.  0.  1.]\n",
            " [ 0.  0.  0. ...,  0.  0.  1.]\n",
            " [ 0.  0.  0. ...,  0.  0.  1.]]\n",
            "Target after preprocessing (one-hot): [[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD-gMWjGYo_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defined shared layers as global variables\n",
        "repeator = RepeatVector(Tx)\n",
        "concatenator = Concatenate(axis=-1)\n",
        "densor1 = Dense(10, activation = \"tanh\")\n",
        "densor2 = Dense(1, activation = \"relu\")\n",
        "activator = Activation(softmax, name='attention_weights') # We are using a custom softmax(axis = 1) loaded in this notebook\n",
        "dotor = Dot(axes = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5B56seVYo_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def one_step_attention(a, s_prev):\n",
        "    \"\"\"\n",
        "    Performs one step of attention: Outputs a context vector computed as a dot product of the attention weights\n",
        "    \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n",
        "    \n",
        "    Arguments:\n",
        "    a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)\n",
        "    s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\n",
        "    \n",
        "    Returns:\n",
        "    context -- context vector, input of the next (post-attetion) LSTM cell\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    s_prev = repeator(s_prev)\n",
        "  \n",
        "    concat = concatenator([a,s_prev])\n",
        "    e = densor1(concat)\n",
        "    energies = densor2(e)\n",
        "    alphas = activator(energies)\n",
        "    context = dotor([alphas,a])\n",
        "\n",
        "    return context"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xh20aykPYo_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_a = 32\n",
        "n_s = 64\n",
        "post_activation_LSTM_cell = LSTM(n_s, return_state = True)\n",
        "output_layer = Dense(len(machine_vocab), activation=softmax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7NFMsE0Yo_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    Tx -- length of the input sequence\n",
        "    Ty -- length of the output sequence\n",
        "    n_a -- hidden state size of the Bi-LSTM\n",
        "    n_s -- hidden state size of the post-attention LSTM\n",
        "    human_vocab_size -- size of the python dictionary \"human_vocab\"\n",
        "    machine_vocab_size -- size of the python dictionary \"machine_vocab\"\n",
        "\n",
        "    Returns:\n",
        "    model -- Keras model instance\n",
        "    \"\"\"\n",
        "    X = Input(shape=(Tx, human_vocab_size))\n",
        "    s0 = Input(shape=(n_s,), name='s0')\n",
        "    c0 = Input(shape=(n_s,), name='c0')\n",
        "    s = s0\n",
        "    c = c0\n",
        "    outputs = []\n",
        "\n",
        "    a = Bidirectional(LSTM(n_a, return_sequences=True),\n",
        "                        input_shape=(Tx, human_vocab_size))(X)\n",
        "    \n",
        "    for t in range(Ty):\n",
        "    \n",
        "        context = one_step_attention(a,s0)\n",
        "        s, _, c = post_activation_LSTM_cell(context, initial_state = [s, c])        \n",
        "        out = output_layer(s)        \n",
        "        outputs.append(out)    \n",
        "    model = Model(inputs=[X,s0,c0],outputs=outputs)\n",
        "    \n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9jkoQhaYo_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LQBk8bVYo_U",
        "colab_type": "code",
        "colab": {},
        "outputId": "aeea3240-2804-4ae7-a5e6-a830d0594cbe"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "____________________________________________________________________________________________________\n",
            "Layer (type)                     Output Shape          Param #     Connected to                     \n",
            "====================================================================================================\n",
            "input_1 (InputLayer)             (None, 30, 37)        0                                            \n",
            "____________________________________________________________________________________________________\n",
            "s0 (InputLayer)                  (None, 64)            0                                            \n",
            "____________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional)  (None, 30, 64)        17920       input_1[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "repeat_vector_1 (RepeatVector)   (None, 30, 64)        0           s0[0][0]                         \n",
            "                                                                   s0[0][0]                         \n",
            "                                                                   s0[0][0]                         \n",
            "                                                                   s0[0][0]                         \n",
            "                                                                   s0[0][0]                         \n",
            "                                                                   s0[0][0]                         \n",
            "                                                                   s0[0][0]                         \n",
            "                                                                   s0[0][0]                         \n",
            "                                                                   s0[0][0]                         \n",
            "                                                                   s0[0][0]                         \n",
            "____________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)      (None, 30, 128)       0           bidirectional_1[0][0]            \n",
            "                                                                   repeat_vector_1[0][0]            \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   repeat_vector_1[1][0]            \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   repeat_vector_1[2][0]            \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   repeat_vector_1[3][0]            \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   repeat_vector_1[4][0]            \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   repeat_vector_1[5][0]            \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   repeat_vector_1[6][0]            \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   repeat_vector_1[7][0]            \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   repeat_vector_1[8][0]            \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   repeat_vector_1[9][0]            \n",
            "____________________________________________________________________________________________________\n",
            "dense_1 (Dense)                  (None, 30, 10)        1290        concatenate_1[0][0]              \n",
            "                                                                   concatenate_1[1][0]              \n",
            "                                                                   concatenate_1[2][0]              \n",
            "                                                                   concatenate_1[3][0]              \n",
            "                                                                   concatenate_1[4][0]              \n",
            "                                                                   concatenate_1[5][0]              \n",
            "                                                                   concatenate_1[6][0]              \n",
            "                                                                   concatenate_1[7][0]              \n",
            "                                                                   concatenate_1[8][0]              \n",
            "                                                                   concatenate_1[9][0]              \n",
            "____________________________________________________________________________________________________\n",
            "dense_2 (Dense)                  (None, 30, 1)         11          dense_1[0][0]                    \n",
            "                                                                   dense_1[1][0]                    \n",
            "                                                                   dense_1[2][0]                    \n",
            "                                                                   dense_1[3][0]                    \n",
            "                                                                   dense_1[4][0]                    \n",
            "                                                                   dense_1[5][0]                    \n",
            "                                                                   dense_1[6][0]                    \n",
            "                                                                   dense_1[7][0]                    \n",
            "                                                                   dense_1[8][0]                    \n",
            "                                                                   dense_1[9][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "attention_weights (Activation)   (None, 30, 1)         0           dense_2[0][0]                    \n",
            "                                                                   dense_2[1][0]                    \n",
            "                                                                   dense_2[2][0]                    \n",
            "                                                                   dense_2[3][0]                    \n",
            "                                                                   dense_2[4][0]                    \n",
            "                                                                   dense_2[5][0]                    \n",
            "                                                                   dense_2[6][0]                    \n",
            "                                                                   dense_2[7][0]                    \n",
            "                                                                   dense_2[8][0]                    \n",
            "                                                                   dense_2[9][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "dot_1 (Dot)                      (None, 1, 64)         0           attention_weights[0][0]          \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   attention_weights[1][0]          \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   attention_weights[2][0]          \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   attention_weights[3][0]          \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   attention_weights[4][0]          \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   attention_weights[5][0]          \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   attention_weights[6][0]          \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   attention_weights[7][0]          \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   attention_weights[8][0]          \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   attention_weights[9][0]          \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "____________________________________________________________________________________________________\n",
            "c0 (InputLayer)                  (None, 64)            0                                            \n",
            "____________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                    [(None, 64), (None, 6 33024       dot_1[0][0]                      \n",
            "                                                                   s0[0][0]                         \n",
            "                                                                   c0[0][0]                         \n",
            "                                                                   dot_1[1][0]                      \n",
            "                                                                   lstm_1[0][0]                     \n",
            "                                                                   lstm_1[0][2]                     \n",
            "                                                                   dot_1[2][0]                      \n",
            "                                                                   lstm_1[1][0]                     \n",
            "                                                                   lstm_1[1][2]                     \n",
            "                                                                   dot_1[3][0]                      \n",
            "                                                                   lstm_1[2][0]                     \n",
            "                                                                   lstm_1[2][2]                     \n",
            "                                                                   dot_1[4][0]                      \n",
            "                                                                   lstm_1[3][0]                     \n",
            "                                                                   lstm_1[3][2]                     \n",
            "                                                                   dot_1[5][0]                      \n",
            "                                                                   lstm_1[4][0]                     \n",
            "                                                                   lstm_1[4][2]                     \n",
            "                                                                   dot_1[6][0]                      \n",
            "                                                                   lstm_1[5][0]                     \n",
            "                                                                   lstm_1[5][2]                     \n",
            "                                                                   dot_1[7][0]                      \n",
            "                                                                   lstm_1[6][0]                     \n",
            "                                                                   lstm_1[6][2]                     \n",
            "                                                                   dot_1[8][0]                      \n",
            "                                                                   lstm_1[7][0]                     \n",
            "                                                                   lstm_1[7][2]                     \n",
            "                                                                   dot_1[9][0]                      \n",
            "                                                                   lstm_1[8][0]                     \n",
            "                                                                   lstm_1[8][2]                     \n",
            "____________________________________________________________________________________________________\n",
            "dense_3 (Dense)                  (None, 11)            715         lstm_1[0][0]                     \n",
            "                                                                   lstm_1[1][0]                     \n",
            "                                                                   lstm_1[2][0]                     \n",
            "                                                                   lstm_1[3][0]                     \n",
            "                                                                   lstm_1[4][0]                     \n",
            "                                                                   lstm_1[5][0]                     \n",
            "                                                                   lstm_1[6][0]                     \n",
            "                                                                   lstm_1[7][0]                     \n",
            "                                                                   lstm_1[8][0]                     \n",
            "                                                                   lstm_1[9][0]                     \n",
            "====================================================================================================\n",
            "Total params: 52,960\n",
            "Trainable params: 52,960\n",
            "Non-trainable params: 0\n",
            "____________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTG9JI1oYo_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### START CODE HERE ### (≈2 lines)\n",
        "opt = Adam(lr=0.005, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
        "### END CODE HERE ###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvfQhho5Yo_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s0 = np.zeros((m, n_s))\n",
        "c0 = np.zeros((m, n_s))\n",
        "outputs = list(Yoh.swapaxes(0,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QLPHUIqYo_j",
        "colab_type": "code",
        "colab": {},
        "outputId": "2fe89d62-8610-4bf8-c117-6f5c1f433a77"
      },
      "source": [
        "model.fit([Xoh, s0, c0], outputs, epochs=1, batch_size=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 44s - loss: 17.0890 - dense_3_loss_1: 1.3235 - dense_3_loss_2: 1.0277 - dense_3_loss_3: 1.7292 - dense_3_loss_4: 2.7498 - dense_3_loss_5: 0.8381 - dense_3_loss_6: 1.3304 - dense_3_loss_7: 2.6926 - dense_3_loss_8: 1.0683 - dense_3_loss_9: 1.7456 - dense_3_loss_10: 2.5839    \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efd2021ab00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJw4xQqbYo_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('models/model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrpqjHwjYo_q",
        "colab_type": "code",
        "colab": {},
        "outputId": "ff51a4bb-cffc-48e9-adf6-9b76a95a80ac"
      },
      "source": [
        "EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\n",
        "for example in EXAMPLES:\n",
        "    \n",
        "    source = string_to_int(example, Tx, human_vocab)\n",
        "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source))).swapaxes(0,1)\n",
        "    prediction = model.predict([source, s0, c0])\n",
        "    prediction = np.argmax(prediction, axis = -1)\n",
        "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
        "    \n",
        "    print(\"source:\", example)\n",
        "    print(\"output:\", ''.join(output))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "source: 3 May 1979\n",
            "output: 1977-07-07\n",
            "source: 5 April 09\n",
            "output: 2009-00-00\n",
            "source: 21th of August 2016\n",
            "output: 2016-02-01\n",
            "source: Tue 10 Jul 2007\n",
            "output: 2000-00-00\n",
            "source: Saturday May 9 2018\n",
            "output: 2010-00-01\n",
            "source: March 3 2001\n",
            "output: 2000-00-00\n",
            "source: March 3rd 2001\n",
            "output: 2000-00-00\n",
            "source: 1 March 2001\n",
            "output: 2000-00-00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz1szvY6Yo_v",
        "colab_type": "code",
        "colab": {},
        "outputId": "fe1f6a97-1dd4-40cb-bd54-2b53111461f1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "____________________________________________________________________________________________________\n",
            "Layer (type)                     Output Shape          Param #     Connected to                     \n",
            "====================================================================================================\n",
            "input_1 (InputLayer)             (None, 30, 37)        0                                            \n",
            "____________________________________________________________________________________________________\n",
            "s0 (InputLayer)                  (None, 64)            0                                            \n",
            "____________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional)  (None, 30, 64)        17920       input_1[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "repeat_vector_1 (RepeatVector)   (None, 30, 64)        0           s0[0][0]                         \n",
            "                                                                   s0[0][0]                         \n",
            "                                                                   s0[0][0]                         \n",
            "                                                                   s0[0][0]                         \n",
            "                                                                   s0[0][0]                         \n",
            "                                                                   s0[0][0]                         \n",
            "                                                                   s0[0][0]                         \n",
            "                                                                   s0[0][0]                         \n",
            "                                                                   s0[0][0]                         \n",
            "                                                                   s0[0][0]                         \n",
            "____________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)      (None, 30, 128)       0           bidirectional_1[0][0]            \n",
            "                                                                   repeat_vector_1[0][0]            \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   repeat_vector_1[1][0]            \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   repeat_vector_1[2][0]            \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   repeat_vector_1[3][0]            \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   repeat_vector_1[4][0]            \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   repeat_vector_1[5][0]            \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   repeat_vector_1[6][0]            \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   repeat_vector_1[7][0]            \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   repeat_vector_1[8][0]            \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   repeat_vector_1[9][0]            \n",
            "____________________________________________________________________________________________________\n",
            "dense_1 (Dense)                  (None, 30, 10)        1290        concatenate_1[0][0]              \n",
            "                                                                   concatenate_1[1][0]              \n",
            "                                                                   concatenate_1[2][0]              \n",
            "                                                                   concatenate_1[3][0]              \n",
            "                                                                   concatenate_1[4][0]              \n",
            "                                                                   concatenate_1[5][0]              \n",
            "                                                                   concatenate_1[6][0]              \n",
            "                                                                   concatenate_1[7][0]              \n",
            "                                                                   concatenate_1[8][0]              \n",
            "                                                                   concatenate_1[9][0]              \n",
            "____________________________________________________________________________________________________\n",
            "dense_2 (Dense)                  (None, 30, 1)         11          dense_1[0][0]                    \n",
            "                                                                   dense_1[1][0]                    \n",
            "                                                                   dense_1[2][0]                    \n",
            "                                                                   dense_1[3][0]                    \n",
            "                                                                   dense_1[4][0]                    \n",
            "                                                                   dense_1[5][0]                    \n",
            "                                                                   dense_1[6][0]                    \n",
            "                                                                   dense_1[7][0]                    \n",
            "                                                                   dense_1[8][0]                    \n",
            "                                                                   dense_1[9][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "attention_weights (Activation)   (None, 30, 1)         0           dense_2[0][0]                    \n",
            "                                                                   dense_2[1][0]                    \n",
            "                                                                   dense_2[2][0]                    \n",
            "                                                                   dense_2[3][0]                    \n",
            "                                                                   dense_2[4][0]                    \n",
            "                                                                   dense_2[5][0]                    \n",
            "                                                                   dense_2[6][0]                    \n",
            "                                                                   dense_2[7][0]                    \n",
            "                                                                   dense_2[8][0]                    \n",
            "                                                                   dense_2[9][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "dot_1 (Dot)                      (None, 1, 64)         0           attention_weights[0][0]          \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   attention_weights[1][0]          \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   attention_weights[2][0]          \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   attention_weights[3][0]          \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   attention_weights[4][0]          \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   attention_weights[5][0]          \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   attention_weights[6][0]          \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   attention_weights[7][0]          \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   attention_weights[8][0]          \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "                                                                   attention_weights[9][0]          \n",
            "                                                                   bidirectional_1[0][0]            \n",
            "____________________________________________________________________________________________________\n",
            "c0 (InputLayer)                  (None, 64)            0                                            \n",
            "____________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                    [(None, 64), (None, 6 33024       dot_1[0][0]                      \n",
            "                                                                   s0[0][0]                         \n",
            "                                                                   c0[0][0]                         \n",
            "                                                                   dot_1[1][0]                      \n",
            "                                                                   lstm_1[0][0]                     \n",
            "                                                                   lstm_1[0][2]                     \n",
            "                                                                   dot_1[2][0]                      \n",
            "                                                                   lstm_1[1][0]                     \n",
            "                                                                   lstm_1[1][2]                     \n",
            "                                                                   dot_1[3][0]                      \n",
            "                                                                   lstm_1[2][0]                     \n",
            "                                                                   lstm_1[2][2]                     \n",
            "                                                                   dot_1[4][0]                      \n",
            "                                                                   lstm_1[3][0]                     \n",
            "                                                                   lstm_1[3][2]                     \n",
            "                                                                   dot_1[5][0]                      \n",
            "                                                                   lstm_1[4][0]                     \n",
            "                                                                   lstm_1[4][2]                     \n",
            "                                                                   dot_1[6][0]                      \n",
            "                                                                   lstm_1[5][0]                     \n",
            "                                                                   lstm_1[5][2]                     \n",
            "                                                                   dot_1[7][0]                      \n",
            "                                                                   lstm_1[6][0]                     \n",
            "                                                                   lstm_1[6][2]                     \n",
            "                                                                   dot_1[8][0]                      \n",
            "                                                                   lstm_1[7][0]                     \n",
            "                                                                   lstm_1[7][2]                     \n",
            "                                                                   dot_1[9][0]                      \n",
            "                                                                   lstm_1[8][0]                     \n",
            "                                                                   lstm_1[8][2]                     \n",
            "____________________________________________________________________________________________________\n",
            "dense_3 (Dense)                  (None, 11)            715         lstm_1[0][0]                     \n",
            "                                                                   lstm_1[1][0]                     \n",
            "                                                                   lstm_1[2][0]                     \n",
            "                                                                   lstm_1[3][0]                     \n",
            "                                                                   lstm_1[4][0]                     \n",
            "                                                                   lstm_1[5][0]                     \n",
            "                                                                   lstm_1[6][0]                     \n",
            "                                                                   lstm_1[7][0]                     \n",
            "                                                                   lstm_1[8][0]                     \n",
            "                                                                   lstm_1[9][0]                     \n",
            "====================================================================================================\n",
            "Total params: 52,960\n",
            "Trainable params: 52,960\n",
            "Non-trainable params: 0\n",
            "____________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "rA1PSETvYo_0",
        "colab_type": "code",
        "colab": {},
        "outputId": "bb89bb45-e769-4250-ca04-b0e019e64b32"
      },
      "source": [
        "attention_map = plot_attention_map(model, human_vocab, inv_machine_vocab, \"Tuesday 09 Oct 1993\", num = 7, n_s = 64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7efd0c1601d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAGsCAYAAAD9ro91AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7efd08100a90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}